{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ejercicio 1 (6 puntos)\n",
    "\n",
    "Programar el método de descenso máximo con tamaño de paso fijo y probarlo.\n",
    " \n",
    "El algoritmo recibe como parámetros la función gradiente $g(x)$ de la función objetivo,\n",
    "un punto inicial $x_0$, el valor del tamaño de paso $\\alpha$, un número  máximo de iteraciones $N$, \n",
    "la tolerancia $\\tau>0$. Fijar $k=0$ y repetir los siguientes pasos:\n",
    "\n",
    "1. Calcular el gradiente $g_k$ en el punto $x_k$, $g_k = g(x_k)$.\n",
    "2. Si $\\|g_k\\| < \\tau$,  hacer  $res=1$ y terminar. \n",
    "3. Elegir la dirección de descenso como $p_k = - g_k$.\n",
    "4. Calcular el siguiente punto de la secuencia como\n",
    "   $$x_{k+1} = x_k + \\alpha p_k $$\n",
    "5. Si $k+1\\geq N$, hacer $res=0$ y terminar.\n",
    "6. Si no, hacer $k = k+1$ y volver el paso 1.\n",
    "7. Devolver el punto $x_k$,  $g_k$, $k$ y $res$.\n",
    "\n",
    "---\n",
    "\n",
    "De acuerdo con la proposición vista en la clase 12, para que el método de\n",
    "máximo descenso con paso fijo para funciones cuadráticas converja \n",
    "se requiere que el tamaño de paso $\\alpha$ cumpla con\n",
    "$$ 0 < \\alpha < \\frac{2}{\\lambda_{\\max}(A)} = \\alpha_{\\max}, $$\n",
    "donde $\\lambda_{\\max}(A)$ es el eigenvalor más grande de $A$.\n",
    "\n",
    "1. Escriba una función que implementa el algoritmo de descenso máximo\n",
    "   con paso fijo.\n",
    "   \n",
    "2. Programe  las funciones cuadráticas y sus gradientes \n",
    "   $$ f_i(x) = \\frac{1}{2} x^\\top \\mathbf{A}_i x - \\mathbf{b}^\\top_i x, \\quad i=1,2 $$\n",
    "   donde \n",
    "   $$ \\mathbf{A}_1 = \\left[ \\begin{array}{cc}\n",
    "   1.18 & 0.69 \\\\\n",
    "   0.69 & 3.01 \n",
    "   \\end{array} \\right],\\qquad \n",
    "   \\mathbf{b}_1 = \\left( \\begin{array}{r} -0.24 \\\\ 0.99 \\end{array} \\right).$$\n",
    "   \n",
    "   y\n",
    "   \n",
    "   $$\\mathbf{A}_2=\\begin{pmatrix}6.36 & -3.07 & -2.8  & -3.42 & -0.68\\\\-3.07 & 10.19 &  0.74 &  0.5  & 0.72\\\\-2.8  & 0.74  &  4.97 & -1.48 & 1.93\\\\-3.42 & 0.5   & -1.48 &  4.9  & -0.97\\\\-0.68 & 0.72  &  1.93 & -0.97 & 3.21\\end{pmatrix},\\qquad\\mathbf{b}_2 = \\left( \\begin{array}{r} 0.66 \\\\ 0.37  \\\\ -2.06  \\\\ 0.14 \\\\ 1.36 \\end{array} \\right).$$\n",
    "\n",
    "3. Fije el número máximo de iteraciones $N=2000$ y la tolerancia $\\tau =\\sqrt{\\epsilon_m}$,\n",
    "   donde $\\epsilon_m$ es el épsilon de la máquina.\n",
    "   Para cada función cuadrática, calcule $\\alpha_{\\max}$ de la matriz $\\mathbf{A}_i$. \n",
    "   Pruebe con los tamaños de paso $\\alpha$ igual a $1.1\\alpha_{\\max}$ y $0.9\\alpha_{\\max}$.\n",
    "   Use el punto inicial \n",
    "   \n",
    "   $$\n",
    "   \\mathbf{x}_0 = \n",
    "   \\left( \\begin{array}{r} -38.12 \\\\ -55.87  \\end{array} \\right) \\quad \\text{para} \\quad f_1\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\mathbf{x}_0 = \n",
    "   \\left( \\begin{array}{r} 4.60 \\\\  6.85 \\\\  4.31 \\\\  4.79 \\\\  8.38  \n",
    "   \\end{array} \\right) \\quad \\text{para} \\quad f_2\n",
    "   $$\n",
    "   \n",
    "4. En cada caso imprima $x_k$, $\\|g_k\\|$, el número de iteraciones $k$ y \n",
    "   el valor de $res$.\n",
    "\n",
    "\n",
    "## Solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de iteraciones que consideraremos en el método de descenso máximo con paso fijo será $N=2000$ y la tolerancia $\\tau=\\sqrt{\\epsilon_m}$, donde $\\epsilon_m$ es el épsilon de la máquina. \n",
    "\n",
    "Calcularemos $\\alpha_{\\max}$ para cada función cuadrática $f_i$. Probaremos el método de descenso máximo con paso fijo con los tamaños de paso $0.9\\alpha_{\\max}$ y $1.1\\alpha_{\\max}$.\n",
    "\n",
    "### Función cuadrática 1\n",
    "\n",
    "Haremos las pruebas correspondientes a la función $f_1$. En primer lugar, determinamos $\\alpha_{\\max}$, además de validar si $\\mathbf{A}_1$ es positiva definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor eigenvalor mínimo es:  0.9489960733051563\n",
      "a_max =  0.6170927420133021\n"
     ]
    }
   ],
   "source": [
    "import lib_t5\n",
    "import importlib\n",
    "importlib.reload(lib_t5)\n",
    "from lib_t5 import *\n",
    "\n",
    "# Iteraciones maximas, tolerancia\n",
    "N=2000\n",
    "tol=np.finfo(float).eps**(1/2)\n",
    "\n",
    "# Matriz y vector modelo cuadrático\n",
    "A1,b1=np.array([[1.18,0.69],[0.69,3.01]]),np.array([-0.24,0.99]).reshape(-1,1)\n",
    "# Condición inicial\n",
    "x0=np.array([-38.12,-55.87]).reshape(-1,1)\n",
    "\n",
    "# Verificar si es positiva definida\n",
    "eig_val_A1=np.real_if_close(np.linalg.eigvals(A1))\n",
    "print('El valor eigenvalor mínimo es: ',np.min(eig_val_A1))\n",
    "# Calcula a_max\n",
    "a_max_1=2.0/np.max(eig_val_A1)\n",
    "print('a_max = ',a_max_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior tenemos que $\\mathbf{A}_1$ es positiva definida, luego el punto crítico es mínimo global. Ahora haremos las pruebas con los distintos tamaños de pasos.\n",
    "\n",
    "#### $0.9\\alpha_{\\max}$\n",
    "Para este tamaño de paso, imprimimos el número de iteraciones, el valor en el mínimo y la distancia respecto al punto crítico para validar que en efecto convergemos al mínimo global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  1\n",
      "El método de descenso máximo con paso fijo CONVERGE\n",
      "k =  105\n",
      "fk =  -0.26949669993822545\n",
      "||gk|| =  1.4137071703555776e-08\n",
      "xk =  [-0.45696914  0.43365738]\n",
      "||xk-x*|| =  4.361942126279292e-09\n"
     ]
    }
   ],
   "source": [
    "proof_grad_max_fix_quad(quad_fun,grad_quad_fun,x0,N,tol,0.9*a_max_1,args=[A1,b1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convergencia esta asegurada por la Proposición de la Clase 12 para cualquier condición inicial pues $0.9\\alpha_{\\max}<\\alpha_{\\max}$, y en este caso la convergencia fue relativamente rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $1.1\\alpha_{\\max}$\n",
    "\n",
    "En este caso no tenemos segura la convergencia, realizamos la misma prueba para este tamaño de paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  0\n",
      "El método de descenso máximo con paso exacto NO CONVERGE\n",
      "k =  2000\n",
      "fk =  inf\n",
      "||gk|| =  inf\n",
      "xk =  [-4.77996787e+159 -1.42775834e+160]\n",
      "||xk-x*|| =  inf\n"
     ]
    }
   ],
   "source": [
    "proof_grad_max_fix_quad(quad_fun,grad_quad_fun,x0,N,tol,1.1*a_max_1,args=[A1,b1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso por completo divergemos, el valor de la función aumenta cada vez más, incluso diverge la norma del gradiente. Nos alejamos tanto del punto crítico que la distancia final respecto al punto crítico es $\\infty$. \n",
    "\n",
    "El cambio fue sutil en el tamaño de paso fijo, pero nos llevó a un resultado degenerado.\n",
    "\n",
    "### Función cuadrática 2\n",
    "\n",
    "Al igual que la función $f_1$, primero validamos si $A_2$ es positiva definida además de calcular $\\alpha_{\\max}$ para esta función cuadrática. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor eigenvalor mínimo es:  0.12547412774810465\n",
      "a_max =  0.1529725843120685\n"
     ]
    }
   ],
   "source": [
    "# Matriz y vector modelo cuadrático\n",
    "A2,b2=np.array([[6.36,-3.07,-2.8,-3.42,-0.68],[-3.07,10.19,0.74,0.5,0.72],[-2.8,0.74,4.97,-1.48,1.93],[-3.42,0.5,-1.48,4.9,-0.97],[-0.68,0.72,1.93,-0.97,3.21]]),np.array([0.66,0.37,-2.06,0.14,1.36]).reshape(-1,1)\n",
    "\n",
    "# Condición inicial\n",
    "x0=np.array([4.60,6.85,4.31,4.79,8.38]).reshape(-1,1)\n",
    "\n",
    "# Verificar si es positiva definida\n",
    "eig_val_A2=np.real_if_close(np.linalg.eigvals(A2))\n",
    "print('El valor eigenvalor mínimo es: ',np.min(eig_val_A2))\n",
    "\n",
    "# Calcula a_max\n",
    "a_max_2=2.0/np.max(eig_val_A2)\n",
    "print('a_max = ',a_max_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del resultado anterior concluimos que $A_2$ es una matriz simétrica positiva definida, luego el punto crítico es óptimo global. Haremos las pruebas con los distintos tamaños de pasos. \n",
    "\n",
    "#### $0.9\\alpha_{\\max}$\n",
    "Imprimimos el número de iteraciones, el valor en el mínimo y la distancia respecto al punto crítico para validar que en efecto convergemos al mínimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  1\n",
      "El método de descenso máximo con paso fijo CONVERGE\n",
      "k =  1064\n",
      "fk =  -2.6497175235052906\n",
      "||gk|| =  1.4711921029622859e-08\n",
      "xk =  [-2.77194407 -0.52190805 -3.05959477 -2.57614049  1.01464594]\n",
      "||xk-x*|| =  1.1725061853105777e-07\n"
     ]
    }
   ],
   "source": [
    "proof_grad_max_fix_quad(quad_fun,grad_quad_fun,x0,N,tol,0.9*a_max_2,args=[A2,b2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sabíamos que la convergencia se obtenía por la proposición de la Clase 12, en este caso tomó más iteraciones que con la función $f_1$ pero esto se puede deber a que $\\alpha_{\\max}$ para $f_2$ es más pequeño que el correspondiente a $f_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $1.1\\alpha_{\\max}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no tenemos segura la convergencia, realizamos la misma prueba para este tamaño de paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  0\n",
      "El método de descenso máximo con paso exacto NO CONVERGE\n",
      "k =  2000\n",
      "fk =  inf\n",
      "||gk|| =  inf\n",
      "xk =  [-7.41437598e+158  9.63088421e+158  3.28353818e+158  2.91033121e+158\n",
      "  1.57034121e+158]\n",
      "||xk-x*|| =  inf\n"
     ]
    }
   ],
   "source": [
    "proof_grad_max_fix_quad(quad_fun,grad_quad_fun,x0,N,tol,1.1*a_max_2,args=[A2,b2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con la función $f_1$, con el tamaño de paso $1.1\\alpha_{\\max}$ el método de descenso máximo con paso fijo diverge, tanto que la norma del gradiente y el valor de la función en la última iteración es infinito, lo que puede significar que con este tamaño de paso, en lugar de reducir el valor de la función este se incrementa cada vez más, a pesar de estar considerando direcciones de descenso pues seguro no se satisface la condición de descenso suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 (4 puntos)\n",
    "\n",
    "Pruebe el método de descenso máximo  con paso fijo aplicado a la \n",
    "función de Rosenbrock.\n",
    "\n",
    "Encuentre un valor adecuado para $\\alpha$ para que el algoritmo \n",
    "converja. Use como punto inicial el punto $(-12, 10)$.\n",
    "\n",
    "Imprima $x_k$, $\\|g_k\\|$, el número de iteraciones $k$ y el valor de $res$.\n",
    "\n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos la prueba del método de descenso máximo con paso fijo con la función de Rosenbrock, del que sabemos tiene su mínimo en $x_\\ast=(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  1\n",
      "El método de descenso máximo con paso fijo CONVERGE\n",
      "k =  1407272\n",
      "fk =  2.77999204102933e-16\n",
      "||gk|| =  1.4901139451473246e-08\n",
      "xk =  [0.99999998 0.99999997]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(lib_t5)\n",
    "from lib_t5 import *\n",
    "x0=np.array([-12.0,10.0]).reshape(-1,1)\n",
    "N=1e7\n",
    "proof_grad_max_fix(f_Rosenbrock,grad_Rosenbrock,x0,N,tol,a=0.000036,args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En efecto, hemos alcanzado convergencia en $k=1,407,272$ iteraciones con tamaño de paso fijo $\\alpha=3.5\\times 10^{-5}$. Como observamos en la tarea anterior, el punto inicial $x_0=(-12,10)$ se encuentra en un valle y relativamente alejado del óptimo, incluso con backtracking no pudimos hallar un tamaño de paso eficiente, así que recurrimos a un tamaño de paso pequeño pero aumentando el número de iteraciones máximas para lograr la convergencia. El tiempo de cómputo para la convergencia fue de 25.4s.\n",
    "\n",
    "Cabe resaltar que con tamaños de paso un poco más grandes se obtienen `NaN`'s al momento de correr el algoritmo, por eso un tamaño de paso chico fue una mejor opción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
